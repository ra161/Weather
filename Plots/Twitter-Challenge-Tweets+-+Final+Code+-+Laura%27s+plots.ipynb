{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "# import visplots\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint\n",
    "import csv\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "from nltk import word_tokenize, wordpunct_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.probability import FreqDist, DictionaryProbDist, ELEProbDist, sum_logs\n",
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "# getting around the ascii characters\n",
    "from django.utils.encoding import smart_str, smart_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the clean tweets (text and date)\n",
    "twitter_raw = pd.read_csv(\"C:\\\\Data\\\\Twitter\\\\Tweets\\\\Clean_Tweets1.csv\", sep=',', delimiter=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete tweets containing key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_cleaned=twitter_raw[twitter_raw['text'].str.lower().str.contains \\\n",
    "                   (\"great smog of london|spanish|sex|porn|anal|pov|bbw|milf|sexy|shemale|sexyfishrestaurant|\\\n",
    "                   nude|sluts|super hot blonde|adult video|erotic|18+|dirty fun|killer fog|rihanna\")==False]\n",
    "\n",
    "twitter_cleaned = twitter_cleaned.reset_index(drop=True)\n",
    "\n",
    "twitter_cleaned['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Machine Learning to clean tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the Maching learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twlist = []\n",
    "\n",
    "with open(r\"C:\\\\Git\\\\Weather\\\\trained_weather_NoRT.csv\", \"r\") as t:\n",
    "    tweets_raw = pd.read_csv(t)\n",
    "\n",
    "tweets = tweets_raw[['text', 'weather']].values.tolist()\n",
    "\n",
    "twlist = [tuple(l) for l in tweets] # turn nested list of lists into list of tuples\n",
    "twtokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (words, weather) in twlist:\n",
    "#    words_filtered = [e.lower().decode('utf8') for e in words.split() if len(e) >= 3 and len(e) <= 10] # and <= 10\n",
    "    words_filtered = [unicode(e.lower(), errors = 'replace') for e in words.split() if len(e) >= 3 and len(e) <= 10] # and <= 10\n",
    "    twtokens.append((words_filtered, weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, weather) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(twtokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Classifier\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    contains(summer���s) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(66%) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(forecast) = False              no : yes    =      1.0 : 1.0\n",
      "     contains(@thedoors) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(@pc24fym) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(infinit...) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(finally) = False              no : yes    =      1.0 : 1.0\n",
      "        contains(1012mb) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(provide) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(@moosawi17) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(mentally) = False              no : yes    =      1.0 : 1.0\n",
      "          contains(#now) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(rainy) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(anthrax) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(youre) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(#oral) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(chick) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(spray) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(jazdy) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(chicken) = False              no : yes    =      1.0 : 1.0\n",
      "        contains(deluxe) = False              no : yes    =      1.0 : 1.0\n",
      "          contains(memo) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(project.) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(12.9��c) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(quick) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(ignor��) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(15c) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(e10) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(dropout) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(proof) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(500) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(#metoffice) = False              no : yes    =      1.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)\n",
    "\n",
    "# train the classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print classifier.show_most_informative_features(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify London Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(twitter_cleaned)\n",
    "\n",
    "tx = df['text']\n",
    "df['text'] = tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal = df[['text']]\n",
    "dffinal['date'] = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:140: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.index)):\n",
    "    if classifier.classify(extract_features((smart_str(df['text'][i])).split())) == 'yes':\n",
    "        dffinal['text'][i] = smart_str(df['text'][i])\n",
    "    else:\n",
    "        dffinal['text'][i] = None\n",
    "\n",
    "count = 0\n",
    "for i in range(len(df.index)):\n",
    "    if dffinal['text'][i] != None:\n",
    "        count += 1\n",
    "\n",
    "count2 = 0\n",
    "dffinaltrained = pd.DataFrame({'date' : pd.Series(range(count), index=range(count)), 'text' : pd.Series(range(count), index=range(count))})\n",
    "for i in range(len(df.index)):\n",
    "    if dffinal['text'][i] != None:\n",
    "        dffinaltrained['text'][count2] = dffinal['text'][i]\n",
    "        dffinaltrained['date'][count2] = dffinal['date'][i]\n",
    "        count2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinaltrained['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function which will count the weather words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wordCount(tweet):\n",
    "    # List of words we are looking at\n",
    "    weather_words = ['breeze', 'breezy', 'cloudy', 'cold', 'ice', 'icy', 'icey', 'drizzle', 'frost', 'wind', 'mild', 'dew', \n",
    "                     'freezing', 'downpour', 'shower', 'rain', 'frost', 'nippy', 'hail', 'temperature', 'gail', 'gust',\n",
    "                     'sleet', 'heat', 'storm', 'slush', 'fog', 'foggy', 'flood', 'visibility', 'warm', 'warmer',\n",
    "                     'mist', 'frosty', 'misty', 'chilly', 'thunder', 'lightning', 'snow', 'snowing', 'hot', 'sun', 'sunny',\n",
    "                     'boiling', 'baltic', 'burn']\n",
    "    # Create a new dictionnary\n",
    "    counts = dict()\n",
    "    for t in tweet:\n",
    "        if t in weather_words:\n",
    "            counts[t] = counts.get(t,0) + 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of final clean tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text\n",
       "date            \n",
       "2016-12-14   300\n",
       "2016-12-15   255\n",
       "2016-12-16   795\n",
       "2016-12-19   791\n",
       "2016-12-20   804\n",
       "2016-12-21   421\n",
       "2016-12-22   463\n",
       "2016-12-23   438\n",
       "2016-12-24   447\n",
       "2016-12-25   460\n",
       "2016-12-26   403\n",
       "2016-12-27   404\n",
       "2016-12-28   466\n",
       "2016-12-30   458\n",
       "2016-12-31   482\n",
       "2017-01-01   431\n",
       "2017-01-02   272\n",
       "2017-01-03   435"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the days and number of tweets per day\n",
    "dffinaltrained.groupby(['date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'2016-12-14', u'2016-12-15', u'2016-12-16', u'2016-12-19',\n",
       "       u'2016-12-20', u'2016-12-21', u'2016-12-22', u'2016-12-23',\n",
       "       u'2016-12-24', u'2016-12-25', u'2016-12-26', u'2016-12-27',\n",
       "       u'2016-12-28', u'2016-12-30', u'2016-12-31', u'2017-01-01',\n",
       "       u'2017-01-02', u'2017-01-03'],\n",
       "      dtype='object', name=u'date')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the date\n",
    "tw_date = dffinaltrained.groupby(['date']).count()\n",
    "tw_date.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going through all tweets then count words and put them in final DataFrame (per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise the final dataframe\n",
    "tw_final = DataFrame()\n",
    "tw_final['date'] = tw_date.index\n",
    "\n",
    "tw_final['Keyword_1'] = None\n",
    "tw_final['Keyword_2'] = None\n",
    "tw_final['Keyword_3'] = None\n",
    "tw_final['Keyword_4'] = None\n",
    "tw_final['Keyword_5'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(tw_date.index)):\n",
    "    df = dffinaltrained[(dffinaltrained['date'] == tw_final['date'][i])]\n",
    "    twitterlist = []\n",
    "    for t in range(len(df.index)):\n",
    "        twitterlist.append(dffinaltrained['text'][t].lower().split())\n",
    "\n",
    "    # Flatten the list so all values in the same list\n",
    "    tweets_flatten = [j for sublist in twitterlist for j in sublist]\n",
    "\n",
    "    # Counting the number of key words in the tweets\n",
    "    d = wordCount(tweets_flatten)\n",
    "    \n",
    "    # give a list of the sorted tweets, with most popular coming first\n",
    "    d2 = sorted(d.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    \n",
    "    tw_final['Keyword_1'][i] = d2[0]#[0]  #keyword 1 is the most popular\n",
    "    tw_final['Keyword_2'][i] = d2[1]#[0]  #keyword 2 is the second most popular\n",
    "    tw_final['Keyword_3'][i] = d2[2]#[0]\n",
    "    tw_final['Keyword_4'][i] = d2[3]#[0]\n",
    "    tw_final['Keyword_5'][i] = d2[4]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Keyword_1</th>\n",
       "      <th>Keyword_2</th>\n",
       "      <th>Keyword_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>(fog, 35)</td>\n",
       "      <td>(hot, 33)</td>\n",
       "      <td>(cold, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>(fog, 31)</td>\n",
       "      <td>(hot, 29)</td>\n",
       "      <td>(sun, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>(hot, 74)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>(hot, 74)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>(hot, 76)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(cold, 63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>(hot, 47)</td>\n",
       "      <td>(sun, 42)</td>\n",
       "      <td>(fog, 42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 49)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>(hot, 50)</td>\n",
       "      <td>(fog, 45)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>(hot, 53)</td>\n",
       "      <td>(fog, 46)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 48)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>(hot, 45)</td>\n",
       "      <td>(fog, 41)</td>\n",
       "      <td>(sun, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>(hot, 45)</td>\n",
       "      <td>(sun, 41)</td>\n",
       "      <td>(fog, 41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 49)</td>\n",
       "      <td>(sun, 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 48)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 50)</td>\n",
       "      <td>(sun, 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>(hot, 49)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(fog, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>(fog, 34)</td>\n",
       "      <td>(sun, 31)</td>\n",
       "      <td>(hot, 29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>(hot, 49)</td>\n",
       "      <td>(fog, 45)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Keyword_1   Keyword_2   Keyword_3\n",
       "0   2016-12-14  (fog, 35)   (hot, 33)  (cold, 33)\n",
       "1   2016-12-15  (fog, 31)   (hot, 29)   (sun, 28)\n",
       "2   2016-12-16  (hot, 74)  (snow, 66)   (fog, 61)\n",
       "3   2016-12-19  (hot, 74)  (snow, 66)   (fog, 61)\n",
       "4   2016-12-20  (hot, 76)  (snow, 66)  (cold, 63)\n",
       "5   2016-12-21  (hot, 47)   (sun, 42)   (fog, 42)\n",
       "6   2016-12-22  (hot, 55)   (fog, 49)   (sun, 45)\n",
       "7   2016-12-23  (hot, 50)   (fog, 45)   (sun, 44)\n",
       "8   2016-12-24  (hot, 53)   (fog, 46)   (sun, 44)\n",
       "9   2016-12-25  (hot, 55)   (fog, 48)   (sun, 45)\n",
       "10  2016-12-26  (hot, 45)   (fog, 41)   (sun, 40)\n",
       "11  2016-12-27  (hot, 45)   (sun, 41)   (fog, 41)\n",
       "12  2016-12-28  (hot, 55)   (fog, 49)   (sun, 46)\n",
       "13  2016-12-30  (hot, 55)   (fog, 48)   (sun, 45)\n",
       "14  2016-12-31  (hot, 55)   (fog, 50)   (sun, 47)\n",
       "15  2017-01-01  (hot, 49)   (sun, 44)   (fog, 43)\n",
       "16  2017-01-02  (fog, 34)   (sun, 31)   (hot, 29)\n",
       "17  2017-01-03  (hot, 49)   (fog, 45)   (sun, 44)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making things simpler\n",
    "tw_final = tw_final.drop(['Keyword_4','Keyword_5'], axis=1)\n",
    "tw_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rahul's Join - Build table with percentage for different keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 76)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank      value\n",
       "0  2016-12-14  Keyword_1  (fog, 35)\n",
       "1  2016-12-15  Keyword_1  (fog, 31)\n",
       "2  2016-12-16  Keyword_1  (hot, 74)\n",
       "3  2016-12-19  Keyword_1  (hot, 74)\n",
       "4  2016-12-20  Keyword_1  (hot, 76)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpivots tw_final\n",
    "tw_final2 = pd.melt(tw_final, id_vars = ['date'])\n",
    "\n",
    "# Rename variable for rank (1 being most popular)\n",
    "tw_final2.rename(columns = {'variable':'rank'}, inplace = True)\n",
    "tw_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split value in tuple then build new columns\n",
    "b = []\n",
    "c = []\n",
    "\n",
    "b.extend(a[1] for a in tw_final2['value'])\n",
    "tw_final2['count'] = b\n",
    "\n",
    "c.extend(a[0] for a in tw_final2['value'])\n",
    "tw_final2['value'] = c\n",
    "\n",
    "#tw_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates dataframe of total tweets for each day\n",
    "df_count = dffinaltrained.groupby(['date']).count()\n",
    "\n",
    "# Resets index\n",
    "df_count.reset_index(level = 0, inplace = True)\n",
    "\n",
    "df_count.rename(columns = {'text':'total_count'}, inplace = True)\n",
    "\n",
    "#df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build final table merged by Joining dataframes tw_final2 and df_count on date\n",
    "merged = pd.merge(tw_final2, df_count, how='inner', on='date')\n",
    "\n",
    "# Creates column for %daily word occurrence\n",
    "merged['%daily word occurrence'] = (merged['count'] / merged['total_count']) * 100\n",
    "\n",
    "# Rename column name Value for Key_word\n",
    "merged.rename(columns = {'value':'key_word'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>key_word</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>%daily word occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>35</td>\n",
       "      <td>300</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_3</td>\n",
       "      <td>cold</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>31</td>\n",
       "      <td>255</td>\n",
       "      <td>12.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>29</td>\n",
       "      <td>255</td>\n",
       "      <td>11.372549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank key_word  count  total_count  %daily word occurrence\n",
       "0  2016-12-14  Keyword_1      fog     35          300               11.666667\n",
       "1  2016-12-14  Keyword_2      hot     33          300               11.000000\n",
       "2  2016-12-14  Keyword_3     cold     33          300               11.000000\n",
       "3  2016-12-15  Keyword_1      fog     31          255               12.156863\n",
       "4  2016-12-15  Keyword_2      hot     29          255               11.372549"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.to_csv(path_or_buf=\"C:\\\\Data\\\\Twitter\\\\Tweets\\\\Daily_Word_Occurrence.csv\", sep=',', na_rep='', \\\n",
    "               float_format=None, columns=['date', 'rank', 'key_word', 'count', 'total_count', '%daily word occurrence'], header=True, index=False, index_label=None, mode='w', encoding=None, \\\n",
    "               compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, \\\n",
    "               date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
    "# Change header = false and mode = a from header = true and mode = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot final results with MetOffice data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import MetOffice data and build join tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot options\n",
    "# init_notebook: On jupyter\n",
    "# plotly : on plotly\n",
    "\n",
    "#init_notebook_mode()\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='Laura_Foulquier', api_key='zehu3fat3Mfs6v3pTNMY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Bucket_Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-07</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Temperature  Bucket_Weather\n",
       "0  2016-12-07           11               2\n",
       "1  2016-12-08           11               2\n",
       "2  2016-12-09           12               2\n",
       "3  2016-12-10           12               3\n",
       "4  2016-12-11            7               1"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the MetOffice Data\n",
    "final_weather = pd.read_csv(\"C:\\\\Data\\\\Twitter\\\\Final_weather_for_plotting.csv\", sep=',', delimiter=None)\n",
    "\n",
    "#Rename Date column for futur join\n",
    "final_weather.rename(columns = {'Date':'date'}, inplace = True)\n",
    "final_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>key_word</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>%daily word occurrence</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Bucket_Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>35</td>\n",
       "      <td>300</td>\n",
       "      <td>11.67</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_3</td>\n",
       "      <td>cold</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>31</td>\n",
       "      <td>255</td>\n",
       "      <td>12.16</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>29</td>\n",
       "      <td>255</td>\n",
       "      <td>11.37</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank key_word  count  total_count  %daily word occurrence  \\\n",
       "0  2016-12-14  Keyword_1      fog     35          300                   11.67   \n",
       "1  2016-12-14  Keyword_2      hot     33          300                   11.00   \n",
       "2  2016-12-14  Keyword_3     cold     33          300                   11.00   \n",
       "3  2016-12-15  Keyword_1      fog     31          255                   12.16   \n",
       "4  2016-12-15  Keyword_2      hot     29          255                   11.37   \n",
       "\n",
       "   Temperature  Bucket_Weather  \n",
       "0           11               1  \n",
       "1           11               1  \n",
       "2           11               1  \n",
       "3            9               2  \n",
       "4            9               2  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join on dates with tweeter results\n",
    "final_results = pd.merge(merged, final_weather, how='inner', on='date')\n",
    "\n",
    "# Reduce the number of decimals to two for plotting \n",
    "for i in range(len(final_results.index)):\n",
    "    final_results['%daily word occurrence'][i] = round(final_results['%daily word occurrence'][i], 2)\n",
    "\n",
    "final_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:27: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Student29\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>key_word</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>%daily word occurrence</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Bucket_Weather</th>\n",
       "      <th>Weather</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>35</td>\n",
       "      <td>300</td>\n",
       "      <td>11.67</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_3</td>\n",
       "      <td>cold</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>31</td>\n",
       "      <td>255</td>\n",
       "      <td>12.16</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>29</td>\n",
       "      <td>255</td>\n",
       "      <td>11.37</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank key_word  count  total_count  %daily word occurrence  \\\n",
       "0  2016-12-14  Keyword_1      fog     35          300                   11.67   \n",
       "1  2016-12-14  Keyword_2      hot     33          300                   11.00   \n",
       "2  2016-12-14  Keyword_3     cold     33          300                   11.00   \n",
       "3  2016-12-15  Keyword_1      fog     31          255                   12.16   \n",
       "4  2016-12-15  Keyword_2      hot     29          255                   11.37   \n",
       "\n",
       "   Temperature  Bucket_Weather Weather  plot  \n",
       "0           11               1   Sunny    16  \n",
       "1           11               1   Sunny    16  \n",
       "2           11               1   Sunny    16  \n",
       "3            9               2  Cloudy    16  \n",
       "4            9               2  Cloudy    16  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert column for Weather depending on Bucket_Weather  number\n",
    "final_results['Weather'] = None\n",
    "\n",
    "for i in range(len(final_results.index)):\n",
    "    if (final_results['Bucket_Weather'][i] == 1) == True:\n",
    "        final_results['Weather'][i] = 'Sunny'\n",
    "\n",
    "    elif (final_results['Bucket_Weather'][i] == 2) == True:\n",
    "        final_results['Weather'][i] = 'Cloudy'\n",
    "    \n",
    "    elif (final_results['Bucket_Weather'][i] == 3) == True:\n",
    "        final_results['Weather'][i] = 'Light Rain'\n",
    "        \n",
    "    elif (final_results['Bucket_Weather'][i] == 4) == True:\n",
    "        final_results['Weather'][i] = 'Heavy Rain'\n",
    "\n",
    "    elif (final_results['Bucket_Weather'][i] == 5) == True:\n",
    "        final_results['Weather'][i] = 'Sleet / Hail'\n",
    "        \n",
    "    elif (final_results['Bucket_Weather'][i] == 6) == True:\n",
    "        final_results['Weather'][i] = 'Snow'\n",
    "\n",
    "    elif (final_results['Bucket_Weather'][i] == 7) == True:\n",
    "        final_results['Weather'][i] = 'Thunder'\n",
    "\n",
    "    elif (final_results['Bucket_Weather'][i] == 8) == True:\n",
    "        final_results['Weather'][i] = 'Fog / Mist'\n",
    "\n",
    "# Column with constant for plotting\n",
    "final_results['plot'] = 16\n",
    "final_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create different tables and arrays for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54L, 10L)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arrays and headers for plotting\n",
    "# Header for plots\n",
    "header = final_results.columns.values\n",
    "\n",
    "npArray = np.array(final_results)\n",
    "npArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the date in X, the rest of the parameter in Y\n",
    "X = npArray[:,0]\n",
    "Y = npArray[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame for rank = Keyword_1\n",
    "rank1 = (final_results[(final_results['rank'] == 'Keyword_1')])\n",
    "rank1 = rank1.reset_index(drop=True)\n",
    "rank1 = rank1.drop(['count','total_count', 'Temperature', 'Bucket_Weather', 'Weather', ], axis=1)\n",
    "\n",
    "npArray = np.array(rank1)\n",
    "X1 = npArray[:,0]\n",
    "Y1 = npArray[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame for rank = Keyword_2\n",
    "rank2 = (final_results[(final_results['rank'] == 'Keyword_2')])\n",
    "rank2 = rank2.reset_index(drop=True)\n",
    "rank2 = rank2.drop(['count','total_count', 'Temperature', 'Bucket_Weather'], axis=1)\n",
    "\n",
    "npArray = np.array(rank2)\n",
    "X2 = npArray[:,0]\n",
    "Y2 = npArray[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DataFrame for rank = Keyword_3\n",
    "rank3 = (final_results[(final_results['rank'] == 'Keyword_3')])\n",
    "rank3 = rank3.reset_index(drop=True)\n",
    "rank3 = rank3.drop(['count','total_count', 'Temperature', 'Bucket_Weather'], axis=1)\n",
    "\n",
    "npArray = np.array(rank3)\n",
    "X3 = npArray[:,0]\n",
    "Y3 = npArray[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Plot temperature vs Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'https://plot.ly/~Laura_Foulquier/6'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting \n",
    "\n",
    "# Plotting the temperature\n",
    "trace0 = go.Scatter(\n",
    "    x = X,\n",
    "    y = Y[:,5],\n",
    "    name = 'Temperature at noon',\n",
    "    yaxis='y2',\n",
    "    line = dict(\n",
    "        color = 'orange',\n",
    "        width = 3\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plotting KeyWord1 occurence and name\n",
    "trace1 = go.Bar(\n",
    "    x = X1,\n",
    "    y = Y1[:,2],\n",
    "    text = Y1[:, 1],\n",
    "    name = 'Occurence Keyword_1',\n",
    "    marker = dict(\n",
    "        color = 'rgb(255,100,100)',\n",
    "        line = dict(\n",
    "            color = 'rgb(255,0,0)',\n",
    "            width = 1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plotting KeyWord2 occurence and name\n",
    "trace2 = go.Bar(\n",
    "    x = X2,\n",
    "    y = Y2[:,2],\n",
    "    text = Y2[:, 1],\n",
    "    name = 'Occurence Keyword_2',\n",
    "    marker = dict(\n",
    "        color = 'rgb(158,202,225)',\n",
    "        line = dict(\n",
    "            color = 'rgb(8,48,107)',\n",
    "            width = 1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plotting KeyWord3 occurence and name\n",
    "trace3 = go.Bar(\n",
    "    x = X3,\n",
    "    y = Y3[:,2],\n",
    "    text = Y3[:, 1],\n",
    "    name = 'Occurence Keyword_3',\n",
    "    marker = dict(\n",
    "        color = 'rgb(100,250,250)',\n",
    "        line = dict(\n",
    "            color = 'rgb(100,200,250)',\n",
    "            width = 1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    title = 'Keywords Occurence from tweets and temperature from MetOffice',\n",
    "    xaxis = dict(\n",
    "        title = 'Date',\n",
    "        tickangle=320,\n",
    "        autotick = 'False',\n",
    "        ticks = 'outside'\n",
    "    ),\n",
    "    yaxis =dict(\n",
    "        title='% of word occurence',\n",
    "        range = [4,16],\n",
    "        autotick = 'False',\n",
    "        ticks = 'outside',\n",
    "        tickfont=dict(\n",
    "            color='rgb(148, 103, 189)',\n",
    "        ) \n",
    "    ),\n",
    "    yaxis2 = dict(\n",
    "        title = 'Temperature',\n",
    "        range = [0,20],\n",
    "        autotick = 'False',\n",
    "        ticks = 'outside',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    showlegend = True,\n",
    "    legend = dict(\n",
    "         x = 0,\n",
    "         y = -0.75\n",
    "    ),\n",
    "    font=dict(family='Old Standard TT, serif', size=14, color='purple')\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "fig = dict(data=data, layout = layout)\n",
    "#iplot(fig)\n",
    "\n",
    "# Put the plot in the plotly account\n",
    "py.plot(fig, filename = 'Keywords Occurence from tweets and temperature from MetOffice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot Actual Weather vs KeyWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'https://plot.ly/~Laura_Foulquier/8'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the actual weather at noon from MetOffice\n",
    "trace0 = go.Scatter(\n",
    "    x = X,\n",
    "    y = Y[:, -1],\n",
    "    text = Y[:, -2],\n",
    "    name = 'MetOffice Weather',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 1,\n",
    "        color = 'blue',\n",
    "        opacity = 0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plotting KeyWord1 occurence and name\n",
    "trace1 = go.Bar(\n",
    "    x = X1,\n",
    "    y = Y1[:,2],\n",
    "    text = Y1[:, 1],\n",
    "    name = 'Occurence Keyword_1',\n",
    "    marker = dict(\n",
    "        color = 'rgb(255,100,100)',\n",
    "        line = dict(\n",
    "            color = 'rgb(255,0,0)',\n",
    "            width = 1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plotting KeyWord2 occurence and name\n",
    "trace2 = go.Bar(\n",
    "    x = X2,\n",
    "    y = Y2[:,2],\n",
    "    text = Y2[:, 1],\n",
    "    name = 'Occurence Keyword_2',\n",
    "    marker = dict(\n",
    "        color = 'rgb(158,202,225)',\n",
    "        line = dict(\n",
    "            color = 'rgb(8,48,107)',\n",
    "            width = 1.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plotting KeyWord3 occurence and name\n",
    "trace3 = go.Bar(\n",
    "    x = X3,\n",
    "    y = Y3[:,2],\n",
    "    text = Y3[:, 1],\n",
    "    name = 'Occurence Keyword_3',\n",
    "    marker = dict(\n",
    "        color = 'rgb(100,250,250)',\n",
    "        line = dict(\n",
    "            color = 'rgb(100,200,250)',\n",
    "            width = 0.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    title = 'Keywords Occurence from tweets and actual weather from MetOffice',\n",
    "    xaxis = dict(\n",
    "        title = 'Date',\n",
    "        tickangle=320,\n",
    "        autotick = 'False',\n",
    "        ticks = 'outside'\n",
    "    ),\n",
    "    yaxis =dict(\n",
    "        title='% of word occurence',\n",
    "        range = [0, 18],\n",
    "        autotick = 'False',\n",
    "        ticks = 'outside',\n",
    "        tickfont=dict(\n",
    "            color='rgb(148, 103, 189)',\n",
    "        ) \n",
    "    ),\n",
    "    showlegend = True,\n",
    "    legend = dict(\n",
    "         x = 0,\n",
    "         y = -0.75\n",
    "    ),\n",
    "    font=dict(family='Old Standard TT, serif', size=14, color='purple')\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "fig = dict(data=data, layout = layout)\n",
    "#iplot(fig)\n",
    "\n",
    "# Put the plot in the plotly account\n",
    "py.plot(fig, filename = 'Keywords Occurence from tweets and actual weather from MetOffice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

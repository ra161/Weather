{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "import plotly.plotly as py\n",
    "# import visplots\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='ra123', api_key='JtjRYEowQy5bMB6Z9lUD')\n",
    "\n",
    "from nltk import word_tokenize, wordpunct_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.probability import FreqDist, DictionaryProbDist, ELEProbDist, sum_logs\n",
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "# getting around the ascii characters\n",
    "from django.utils.encoding import smart_str, smart_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the clean tweets (text and date, then through machine learning)\n",
    "twitter_raw = pd.read_csv(\"C:\\\\Users\\\\Student24\\\\Documents\\\\twitter\\\\useing\\\\Clean_Tweets1.csv\", sep=',', delimiter=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete tweets containing key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8940"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_cleaned=twitter_raw[twitter_raw['text'].str.lower().str.contains \\\n",
    "                   (\"great smog of london|spanish|sex|porn|anal|pov|bbw|milf|sexy|shemale|sexyfishrestaurant|\\\n",
    "                   nude|sluts|super hot blonde|adult video|erotic|18+|dirty fun|killer fog|rihanna\")==False]\n",
    "\n",
    "twitter_cleaned = twitter_cleaned.reset_index(drop=True)\n",
    "\n",
    "twitter_cleaned['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Machine Learning to clean tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the Maching learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twlist = []\n",
    "\n",
    "with open(r\"C:\\\\Users\\\\Student24\\\\Documents\\\\twitter\\\\trained_weather_NoRT.csv\", \"r\") as t:\n",
    "    tweets_raw = pd.read_csv(t)\n",
    "\n",
    "tweets = tweets_raw[['text', 'weather']].values.tolist()\n",
    "\n",
    "twlist = [tuple(l) for l in tweets] # turn nested list of lists into list of tuples\n",
    "twtokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (words, weather) in twlist:\n",
    "#    words_filtered = [e.lower().decode('utf8') for e in words.split() if len(e) >= 3 and len(e) <= 10] # and <= 10\n",
    "    words_filtered = [unicode(e.lower(), errors = 'replace') for e in words.split() if len(e) >= 3 and len(e) <= 10] # and <= 10\n",
    "    twtokens.append((words_filtered, weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, weather) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(twtokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Classifier\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    contains(summer���s) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(66%) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(forecast) = False              no : yes    =      1.0 : 1.0\n",
      "     contains(@thedoors) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(@pc24fym) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(infinit...) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(finally) = False              no : yes    =      1.0 : 1.0\n",
      "        contains(1012mb) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(provide) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(@moosawi17) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(mentally) = False              no : yes    =      1.0 : 1.0\n",
      "          contains(#now) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(rainy) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(anthrax) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(youre) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(#oral) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(chick) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(spray) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(jazdy) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(chicken) = False              no : yes    =      1.0 : 1.0\n",
      "        contains(deluxe) = False              no : yes    =      1.0 : 1.0\n",
      "          contains(memo) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(project.) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(12.9��c) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(quick) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(ignor��) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(15c) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(e10) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(dropout) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(proof) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(500) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(#metoffice) = False              no : yes    =      1.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)\n",
    "\n",
    "# train the classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print classifier.show_most_informative_features(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify London Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(twitter_cleaned)\n",
    "\n",
    "tx = df['text']\n",
    "df['text'] = tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal = df[['text']]\n",
    "dffinal['date'] = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student24\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\Student24\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:132: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.index)):\n",
    "    if classifier.classify(extract_features((smart_str(df['text'][i])).split())) == 'yes':\n",
    "        dffinal['text'][i] = smart_str(df['text'][i])\n",
    "    else:\n",
    "        dffinal['text'][i] = None\n",
    "\n",
    "count = 0\n",
    "for i in range(len(df.index)):\n",
    "    if dffinal['text'][i] != None:\n",
    "        count += 1\n",
    "\n",
    "count2 = 0\n",
    "dffinaltrained = pd.DataFrame({'date' : pd.Series(range(count), index=range(count)), 'text' : pd.Series(range(count), index=range(count))})\n",
    "for i in range(len(df.index)):\n",
    "    if dffinal['text'][i] != None:\n",
    "        dffinaltrained['text'][count2] = dffinal['text'][i]\n",
    "        dffinaltrained['date'][count2] = dffinal['date'][i]\n",
    "        count2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8093"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinaltrained['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function which will count the weather words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wordCount(tweet):\n",
    "    # List of words we are looking at\n",
    "    weather_words = ['breeze', 'breezy', 'cloudy', 'cold', 'ice', 'icy', 'icey', 'drizzle', 'frost', 'wind', 'mild', 'dew', \n",
    "                     'freezing', 'downpour', 'shower', 'rain', 'frost', 'nippy', 'hail', 'temperature', 'gail', 'gust',\n",
    "                     'sleet', 'heat', 'storm', 'slush', 'fog', 'foggy', 'flood', 'visibility', 'warm', 'warmer',\n",
    "                     'mist', 'frosty', 'misty', 'chilly', 'thunder', 'lightning', 'snow', 'snowing', 'hot', 'sun', 'sunny',\n",
    "                     'boiling', 'baltic', 'burn']\n",
    "    # Create a new dictionnary\n",
    "    counts = dict()\n",
    "    for t in tweet:\n",
    "        if t in weather_words:\n",
    "            counts[t] = counts.get(t,0) + 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of final clean tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2017</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/01/2017</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14/12/2016</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15/12/2016</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/12/2016</th>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19/12/2016</th>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20/12/2016</th>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21/12/2016</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22/12/2016</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23/12/2016</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24/12/2016</th>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25/12/2016</th>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26/12/2016</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27/12/2016</th>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/12/2016</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/12/2016</th>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2016</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text\n",
       "date            \n",
       "01/01/2017   431\n",
       "02/01/2017   272\n",
       "14/12/2016   300\n",
       "15/12/2016   255\n",
       "16/12/2016   795\n",
       "19/12/2016   791\n",
       "20/12/2016   804\n",
       "21/12/2016   421\n",
       "22/12/2016   463\n",
       "23/12/2016   438\n",
       "24/12/2016   447\n",
       "25/12/2016   460\n",
       "26/12/2016   403\n",
       "27/12/2016   404\n",
       "28/12/2016   466\n",
       "30/12/2016   458\n",
       "31/12/2016   482"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the days and number of tweets per day\n",
    "dffinaltrained.groupby(['date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'01/01/2017', u'02/01/2017', u'14/12/2016', u'15/12/2016',\n",
       "       u'16/12/2016', u'19/12/2016', u'20/12/2016', u'21/12/2016',\n",
       "       u'22/12/2016', u'23/12/2016', u'24/12/2016', u'25/12/2016',\n",
       "       u'26/12/2016', u'27/12/2016', u'28/12/2016', u'30/12/2016',\n",
       "       u'31/12/2016'],\n",
       "      dtype='object', name=u'date')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the date\n",
    "tw_date = dffinaltrained.groupby(['date']).count()\n",
    "tw_date.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_date['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going through all tweets then count words and put them in final DataFrame (per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise the final dataframe\n",
    "tw_final = DataFrame()\n",
    "tw_final['date'] = tw_date.index\n",
    "\n",
    "tw_final['Keyword_1'] = None\n",
    "tw_final['Keyword_2'] = None\n",
    "tw_final['Keyword_3'] = None\n",
    "tw_final['Keyword_4'] = None\n",
    "tw_final['Keyword_5'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(tw_date.index)):\n",
    "    df = dffinaltrained[(dffinaltrained['date'] == tw_final['date'][i])]\n",
    "    twitterlist = []\n",
    "    for t in range(len(df.index)):\n",
    "        twitterlist.append(dffinaltrained['text'][t].lower().split())\n",
    "\n",
    "    # Flatten the list so all values in the same list\n",
    "    tweets_flatten = [j for sublist in twitterlist for j in sublist]\n",
    "\n",
    "    # Counting the number of key words in the tweets\n",
    "    d = wordCount(tweets_flatten)\n",
    "    \n",
    "    # give a list of the sorted tweets, with most popular coming first\n",
    "    d2 = sorted(d.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    \n",
    "    tw_final['Keyword_1'][i] = d2[0]#[0]  #keyword 1 is the most popular\n",
    "    tw_final['Keyword_2'][i] = d2[1]#[0]  #keyword 2 is the second most popular\n",
    "    tw_final['Keyword_3'][i] = d2[2]#[0]\n",
    "    tw_final['Keyword_4'][i] = d2[3]#[0]\n",
    "    tw_final['Keyword_5'][i] = d2[4]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Keyword_1</th>\n",
       "      <th>Keyword_2</th>\n",
       "      <th>Keyword_3</th>\n",
       "      <th>Keyword_4</th>\n",
       "      <th>Keyword_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>(hot, 49)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(fog, 43)</td>\n",
       "      <td>(cold, 41)</td>\n",
       "      <td>(warm, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2017</td>\n",
       "      <td>(fog, 34)</td>\n",
       "      <td>(sun, 31)</td>\n",
       "      <td>(hot, 29)</td>\n",
       "      <td>(cold, 29)</td>\n",
       "      <td>(warm, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>(fog, 35)</td>\n",
       "      <td>(hot, 33)</td>\n",
       "      <td>(cold, 33)</td>\n",
       "      <td>(sun, 32)</td>\n",
       "      <td>(warm, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>(fog, 31)</td>\n",
       "      <td>(hot, 29)</td>\n",
       "      <td>(sun, 28)</td>\n",
       "      <td>(cold, 28)</td>\n",
       "      <td>(warm, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>(hot, 74)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "      <td>(cold, 60)</td>\n",
       "      <td>(sun, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19/12/2016</td>\n",
       "      <td>(hot, 74)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "      <td>(cold, 60)</td>\n",
       "      <td>(sun, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20/12/2016</td>\n",
       "      <td>(hot, 76)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(cold, 63)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "      <td>(sun, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21/12/2016</td>\n",
       "      <td>(hot, 47)</td>\n",
       "      <td>(sun, 42)</td>\n",
       "      <td>(fog, 42)</td>\n",
       "      <td>(cold, 41)</td>\n",
       "      <td>(warm, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22/12/2016</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 49)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "      <td>(cold, 43)</td>\n",
       "      <td>(warm, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23/12/2016</td>\n",
       "      <td>(hot, 50)</td>\n",
       "      <td>(fog, 45)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(cold, 41)</td>\n",
       "      <td>(warm, 29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24/12/2016</td>\n",
       "      <td>(hot, 53)</td>\n",
       "      <td>(fog, 46)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(cold, 42)</td>\n",
       "      <td>(warm, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25/12/2016</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 48)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "      <td>(cold, 43)</td>\n",
       "      <td>(warm, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26/12/2016</td>\n",
       "      <td>(hot, 45)</td>\n",
       "      <td>(fog, 41)</td>\n",
       "      <td>(sun, 40)</td>\n",
       "      <td>(cold, 39)</td>\n",
       "      <td>(warm, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27/12/2016</td>\n",
       "      <td>(hot, 45)</td>\n",
       "      <td>(sun, 41)</td>\n",
       "      <td>(fog, 41)</td>\n",
       "      <td>(cold, 39)</td>\n",
       "      <td>(warm, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28/12/2016</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 49)</td>\n",
       "      <td>(sun, 46)</td>\n",
       "      <td>(cold, 43)</td>\n",
       "      <td>(warm, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30/12/2016</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 48)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "      <td>(cold, 42)</td>\n",
       "      <td>(warm, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 50)</td>\n",
       "      <td>(sun, 47)</td>\n",
       "      <td>(cold, 44)</td>\n",
       "      <td>(warm, 35)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Keyword_1   Keyword_2   Keyword_3   Keyword_4   Keyword_5\n",
       "0   01/01/2017  (hot, 49)   (sun, 44)   (fog, 43)  (cold, 41)  (warm, 28)\n",
       "1   02/01/2017  (fog, 34)   (sun, 31)   (hot, 29)  (cold, 29)  (warm, 16)\n",
       "2   14/12/2016  (fog, 35)   (hot, 33)  (cold, 33)   (sun, 32)  (warm, 17)\n",
       "3   15/12/2016  (fog, 31)   (hot, 29)   (sun, 28)  (cold, 28)  (warm, 16)\n",
       "4   16/12/2016  (hot, 74)  (snow, 66)   (fog, 61)  (cold, 60)   (sun, 60)\n",
       "5   19/12/2016  (hot, 74)  (snow, 66)   (fog, 61)  (cold, 60)   (sun, 60)\n",
       "6   20/12/2016  (hot, 76)  (snow, 66)  (cold, 63)   (fog, 61)   (sun, 60)\n",
       "7   21/12/2016  (hot, 47)   (sun, 42)   (fog, 42)  (cold, 41)  (warm, 28)\n",
       "8   22/12/2016  (hot, 55)   (fog, 49)   (sun, 45)  (cold, 43)  (warm, 32)\n",
       "9   23/12/2016  (hot, 50)   (fog, 45)   (sun, 44)  (cold, 41)  (warm, 29)\n",
       "10  24/12/2016  (hot, 53)   (fog, 46)   (sun, 44)  (cold, 42)  (warm, 30)\n",
       "11  25/12/2016  (hot, 55)   (fog, 48)   (sun, 45)  (cold, 43)  (warm, 31)\n",
       "12  26/12/2016  (hot, 45)   (fog, 41)   (sun, 40)  (cold, 39)  (warm, 25)\n",
       "13  27/12/2016  (hot, 45)   (sun, 41)   (fog, 41)  (cold, 39)  (warm, 25)\n",
       "14  28/12/2016  (hot, 55)   (fog, 49)   (sun, 46)  (cold, 43)  (warm, 32)\n",
       "15  30/12/2016  (hot, 55)   (fog, 48)   (sun, 45)  (cold, 42)  (warm, 31)\n",
       "16  31/12/2016  (hot, 55)   (fog, 50)   (sun, 47)  (cold, 44)  (warm, 35)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot and Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unpivots tw_final\n",
    "tw_final2 = pd.melt(tw_final, id_vars = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2017</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 74)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   variable      value\n",
       "0  01/01/2017  Keyword_1  (hot, 49)\n",
       "1  02/01/2017  Keyword_1  (fog, 34)\n",
       "2  14/12/2016  Keyword_1  (fog, 35)\n",
       "3  15/12/2016  Keyword_1  (fog, 31)\n",
       "4  16/12/2016  Keyword_1  (hot, 74)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw_final2.rename(columns = {'variable':'rank'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seperates tuples in value\n",
    "b = []\n",
    "c = []\n",
    "\n",
    "b.extend(a[1] for a in tw_final2['value'])\n",
    "tw_final2['count'] = b\n",
    "\n",
    "c.extend(a[0] for a in tw_final2['value'])\n",
    "tw_final2['value'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>hot</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2017</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>hot</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank value  count\n",
       "0  01/01/2017  Keyword_1   hot     49\n",
       "1  02/01/2017  Keyword_1   fog     34\n",
       "2  14/12/2016  Keyword_1   fog     35\n",
       "3  15/12/2016  Keyword_1   fog     31\n",
       "4  16/12/2016  Keyword_1   hot     74"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates dataframe of total tweets for each day\n",
    "df_count = dffinaltrained.groupby(['date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resets index\n",
    "df_count.reset_index(level = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_count.rename(columns = {'text':'total_count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2017</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  total_count\n",
       "0  01/01/2017          431\n",
       "1  02/01/2017          272\n",
       "2  14/12/2016          300\n",
       "3  15/12/2016          255\n",
       "4  16/12/2016          795"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joins dataframes tw_final2 and df_count on date\n",
    "merged = pd.merge(tw_final2, df_count, how='inner', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates column for %daily word occurrence\n",
    "merged['%daily word occurrence'] = (merged['count'] / merged['total_count']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.rename(columns = {'value':'key_word'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>key_word</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>%daily word occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>hot</td>\n",
       "      <td>49</td>\n",
       "      <td>431</td>\n",
       "      <td>11.368910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>sun</td>\n",
       "      <td>44</td>\n",
       "      <td>431</td>\n",
       "      <td>10.208817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_3</td>\n",
       "      <td>fog</td>\n",
       "      <td>43</td>\n",
       "      <td>431</td>\n",
       "      <td>9.976798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_4</td>\n",
       "      <td>cold</td>\n",
       "      <td>41</td>\n",
       "      <td>431</td>\n",
       "      <td>9.512761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Keyword_5</td>\n",
       "      <td>warm</td>\n",
       "      <td>28</td>\n",
       "      <td>431</td>\n",
       "      <td>6.496520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank key_word  count  total_count  %daily word occurrence\n",
       "0  01/01/2017  Keyword_1      hot     49          431               11.368910\n",
       "1  01/01/2017  Keyword_2      sun     44          431               10.208817\n",
       "2  01/01/2017  Keyword_3      fog     43          431                9.976798\n",
       "3  01/01/2017  Keyword_4     cold     41          431                9.512761\n",
       "4  01/01/2017  Keyword_5     warm     28          431                6.496520"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv(path_or_buf=\"C:\\\\Users\\\\Student24\\\\Documents\\\\twitter\\\\useing\\\\Daily_Word_Occurrence.csv\", sep=',', na_rep='', \\\n",
    "               float_format=None, columns=['date', 'rank', 'key_word', 'count', 'total_count', '%daily word occurrence'], header=True, index=False, index_label=None, mode='w', encoding=None, \\\n",
    "               compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, \\\n",
    "               date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
    "# Change header = false and mode = a from header = true and mode = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date vs Count |Table+Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_piv=merged.pivot(index='date',columns='key_word', values='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_piv.reset_index(level = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>key_word</th>\n",
       "      <th>date</th>\n",
       "      <th>cold</th>\n",
       "      <th>fog</th>\n",
       "      <th>hot</th>\n",
       "      <th>snow</th>\n",
       "      <th>sun</th>\n",
       "      <th>warm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>41.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2017</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19/12/2016</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20/12/2016</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21/12/2016</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22/12/2016</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23/12/2016</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24/12/2016</td>\n",
       "      <td>42.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25/12/2016</td>\n",
       "      <td>43.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26/12/2016</td>\n",
       "      <td>39.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27/12/2016</td>\n",
       "      <td>39.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28/12/2016</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30/12/2016</td>\n",
       "      <td>42.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "key_word        date  cold   fog   hot  snow   sun  warm\n",
       "0         01/01/2017  41.0  43.0  49.0   NaN  44.0  28.0\n",
       "1         02/01/2017  29.0  34.0  29.0   NaN  31.0  16.0\n",
       "2         14/12/2016  33.0  35.0  33.0   NaN  32.0  17.0\n",
       "3         15/12/2016  28.0  31.0  29.0   NaN  28.0  16.0\n",
       "4         16/12/2016  60.0  61.0  74.0  66.0  60.0   NaN\n",
       "5         19/12/2016  60.0  61.0  74.0  66.0  60.0   NaN\n",
       "6         20/12/2016  63.0  61.0  76.0  66.0  60.0   NaN\n",
       "7         21/12/2016  41.0  42.0  47.0   NaN  42.0  28.0\n",
       "8         22/12/2016  43.0  49.0  55.0   NaN  45.0  32.0\n",
       "9         23/12/2016  41.0  45.0  50.0   NaN  44.0  29.0\n",
       "10        24/12/2016  42.0  46.0  53.0   NaN  44.0  30.0\n",
       "11        25/12/2016  43.0  48.0  55.0   NaN  45.0  31.0\n",
       "12        26/12/2016  39.0  41.0  45.0   NaN  40.0  25.0\n",
       "13        27/12/2016  39.0  41.0  45.0   NaN  41.0  25.0\n",
       "14        28/12/2016  43.0  49.0  55.0   NaN  46.0  32.0\n",
       "15        30/12/2016  42.0  48.0  55.0   NaN  45.0  31.0\n",
       "16        31/12/2016  44.0  50.0  55.0   NaN  47.0  35.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17L, 7L)\n"
     ]
    }
   ],
   "source": [
    "# convert the df to a numpy array\n",
    "np_counts = np.array(merged_piv)\n",
    "print np_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'https://plot.ly/~ra123/8'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to plot count for keywords for each date. Code will update if any new keywords are added to table.\n",
    "trace=[]\n",
    "col_num = len(merged_piv.columns) #Number of columns in dataframe to use in for loop\n",
    "for i in range(col_num):\n",
    "    if i==0:\n",
    "        x_date=np_counts[:,i] # Sets the x-axis as the date\n",
    "    else:\n",
    "        y_count=np_counts[:,i].astype(float) #Sets y-axis as count\n",
    "        trace.append(Scatter( x=x_date, y=y_count, name=merged_piv.dtypes.index[i] )) #appends list 'trace' with counts for each keyword\n",
    "        \n",
    "        \n",
    "        \n",
    "data = Data(trace) #list trace is not data for plotly plot\n",
    "layout = go.Layout( #layout of plotly plot\n",
    "    title='Occurrence of keywords for top 5 keywords per day',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Count',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.plot(fig, filename = 'Occurrence_of_all_keywords') #plotly plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date vs %_of_Count |Table+Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>key_word</th>\n",
       "      <th>date</th>\n",
       "      <th>cold</th>\n",
       "      <th>fog</th>\n",
       "      <th>hot</th>\n",
       "      <th>snow</th>\n",
       "      <th>sun</th>\n",
       "      <th>warm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>9.512761</td>\n",
       "      <td>9.976798</td>\n",
       "      <td>11.368910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.208817</td>\n",
       "      <td>6.496520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2017</td>\n",
       "      <td>10.661765</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>10.661765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.397059</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/12/2016</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/12/2016</td>\n",
       "      <td>10.980392</td>\n",
       "      <td>12.156863</td>\n",
       "      <td>11.372549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.980392</td>\n",
       "      <td>6.274510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2016</td>\n",
       "      <td>7.547170</td>\n",
       "      <td>7.672956</td>\n",
       "      <td>9.308176</td>\n",
       "      <td>8.301887</td>\n",
       "      <td>7.547170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19/12/2016</td>\n",
       "      <td>7.585335</td>\n",
       "      <td>7.711757</td>\n",
       "      <td>9.355247</td>\n",
       "      <td>8.343869</td>\n",
       "      <td>7.585335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20/12/2016</td>\n",
       "      <td>7.835821</td>\n",
       "      <td>7.587065</td>\n",
       "      <td>9.452736</td>\n",
       "      <td>8.208955</td>\n",
       "      <td>7.462687</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21/12/2016</td>\n",
       "      <td>9.738717</td>\n",
       "      <td>9.976247</td>\n",
       "      <td>11.163895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.976247</td>\n",
       "      <td>6.650831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22/12/2016</td>\n",
       "      <td>9.287257</td>\n",
       "      <td>10.583153</td>\n",
       "      <td>11.879050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.719222</td>\n",
       "      <td>6.911447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23/12/2016</td>\n",
       "      <td>9.360731</td>\n",
       "      <td>10.273973</td>\n",
       "      <td>11.415525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.045662</td>\n",
       "      <td>6.621005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24/12/2016</td>\n",
       "      <td>9.395973</td>\n",
       "      <td>10.290828</td>\n",
       "      <td>11.856823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.843400</td>\n",
       "      <td>6.711409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25/12/2016</td>\n",
       "      <td>9.347826</td>\n",
       "      <td>10.434783</td>\n",
       "      <td>11.956522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.782609</td>\n",
       "      <td>6.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26/12/2016</td>\n",
       "      <td>9.677419</td>\n",
       "      <td>10.173697</td>\n",
       "      <td>11.166253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.925558</td>\n",
       "      <td>6.203474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27/12/2016</td>\n",
       "      <td>9.653465</td>\n",
       "      <td>10.148515</td>\n",
       "      <td>11.138614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.148515</td>\n",
       "      <td>6.188119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28/12/2016</td>\n",
       "      <td>9.227468</td>\n",
       "      <td>10.515021</td>\n",
       "      <td>11.802575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.871245</td>\n",
       "      <td>6.866953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30/12/2016</td>\n",
       "      <td>9.170306</td>\n",
       "      <td>10.480349</td>\n",
       "      <td>12.008734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.825328</td>\n",
       "      <td>6.768559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>9.128631</td>\n",
       "      <td>10.373444</td>\n",
       "      <td>11.410788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.751037</td>\n",
       "      <td>7.261411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "key_word        date       cold        fog        hot      snow        sun  \\\n",
       "0         01/01/2017   9.512761   9.976798  11.368910       NaN  10.208817   \n",
       "1         02/01/2017  10.661765  12.500000  10.661765       NaN  11.397059   \n",
       "2         14/12/2016  11.000000  11.666667  11.000000       NaN  10.666667   \n",
       "3         15/12/2016  10.980392  12.156863  11.372549       NaN  10.980392   \n",
       "4         16/12/2016   7.547170   7.672956   9.308176  8.301887   7.547170   \n",
       "5         19/12/2016   7.585335   7.711757   9.355247  8.343869   7.585335   \n",
       "6         20/12/2016   7.835821   7.587065   9.452736  8.208955   7.462687   \n",
       "7         21/12/2016   9.738717   9.976247  11.163895       NaN   9.976247   \n",
       "8         22/12/2016   9.287257  10.583153  11.879050       NaN   9.719222   \n",
       "9         23/12/2016   9.360731  10.273973  11.415525       NaN  10.045662   \n",
       "10        24/12/2016   9.395973  10.290828  11.856823       NaN   9.843400   \n",
       "11        25/12/2016   9.347826  10.434783  11.956522       NaN   9.782609   \n",
       "12        26/12/2016   9.677419  10.173697  11.166253       NaN   9.925558   \n",
       "13        27/12/2016   9.653465  10.148515  11.138614       NaN  10.148515   \n",
       "14        28/12/2016   9.227468  10.515021  11.802575       NaN   9.871245   \n",
       "15        30/12/2016   9.170306  10.480349  12.008734       NaN   9.825328   \n",
       "16        31/12/2016   9.128631  10.373444  11.410788       NaN   9.751037   \n",
       "\n",
       "key_word      warm  \n",
       "0         6.496520  \n",
       "1         5.882353  \n",
       "2         5.666667  \n",
       "3         6.274510  \n",
       "4              NaN  \n",
       "5              NaN  \n",
       "6              NaN  \n",
       "7         6.650831  \n",
       "8         6.911447  \n",
       "9         6.621005  \n",
       "10        6.711409  \n",
       "11        6.739130  \n",
       "12        6.203474  \n",
       "13        6.188119  \n",
       "14        6.866953  \n",
       "15        6.768559  \n",
       "16        7.261411  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_piv_2=merged.pivot(index='date',columns='key_word', values='%daily word occurrence')\n",
    "merged_piv_2.reset_index(level = 0, inplace = True)\n",
    "merged_piv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17L, 7L)\n"
     ]
    }
   ],
   "source": [
    "# convert the df to a numpy array\n",
    "np_counts_2 = np.array(merged_piv_2)\n",
    "print np_counts_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'https://plot.ly/~ra123/10'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to plot count for keywords for each date. Code will update if any new keywords are added to table.\n",
    "trace_2=[]\n",
    "col_num_2 = len(merged_piv_2.columns) #Number of columns in dataframe to use in for loop\n",
    "for i in range(col_num_2):\n",
    "    if i==0:\n",
    "        x_date_2=np_counts_2[:,i] # Sets the x-axis as the date\n",
    "    else:\n",
    "        y_count_2=np_counts_2[:,i].astype(float) #Sets y-axis as count\n",
    "        trace_2.append(Scatter( x=x_date_2, y=y_count_2, name=merged_piv_2.dtypes.index[i] )) #appends list 'trace' with counts for each keyword\n",
    "        \n",
    "        \n",
    "        \n",
    "data_2 = Data(trace_2) #list trace is not data for plotly plot\n",
    "layout_2 = go.Layout( #layout of plotly plot\n",
    "    title='% of keywords for top 5 keywords per day',\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='%',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig_2 = go.Figure(data=data_2, layout=layout_2)\n",
    "py.plot(fig_2, filename = '%_of_all_keywords') #plotly plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

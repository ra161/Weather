{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "# import visplots\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint\n",
    "import csv\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "from nltk import word_tokenize, wordpunct_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.probability import FreqDist, DictionaryProbDist, ELEProbDist, sum_logs\n",
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "# getting around the ascii characters\n",
    "from django.utils.encoding import smart_str, smart_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the clean tweets (text and date, then through machine learning)\n",
    "twitter_raw = pd.read_csv(\"C:\\\\Users\\\\Student21\\\\Documents\\\\Training\\\\Weather Project\\\\Final Classify\\\\Clean_Tweets1.csv\", sep=',', delimiter=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete tweets containing key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8940"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_cleaned=twitter_raw[twitter_raw['text'].str.lower().str.contains \\\n",
    "                   (\"great smog of london|spanish|sex|porn|anal|pov|bbw|milf|sexy|shemale|sexyfishrestaurant|\\\n",
    "                   nude|sluts|super hot blonde|adult video|erotic|18+|dirty fun|killer fog|rihanna\")==False]\n",
    "\n",
    "twitter_cleaned = twitter_cleaned.reset_index(drop=True)\n",
    "\n",
    "twitter_cleaned['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Machine Learning to clean tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the Maching learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twlist = []\n",
    "\n",
    "with open(r\"C:\\\\Users\\\\Student21\\\\Documents\\\\Training\\\\Weather Project\\\\trained_weather_NoRT.csv\", \"r\") as t:\n",
    "    tweets_raw = pd.read_csv(t)\n",
    "\n",
    "tweets = tweets_raw[['text', 'weather']].values.tolist()\n",
    "\n",
    "twlist = [tuple(l) for l in tweets] # turn nested list of lists into list of tuples\n",
    "twtokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (words, weather) in twlist:\n",
    "#    words_filtered = [e.lower().decode('utf8') for e in words.split() if len(e) >= 3 and len(e) <= 10] # and <= 10\n",
    "    words_filtered = [unicode(e.lower(), errors = 'replace') for e in words.split() if len(e) >= 3 and len(e) <= 10] # and <= 10\n",
    "    twtokens.append((words_filtered, weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, weather) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(twtokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Classifier\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    contains(summer���s) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(66%) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(forecast) = False              no : yes    =      1.0 : 1.0\n",
      "     contains(@thedoors) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(@pc24fym) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(infinit...) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(finally) = False              no : yes    =      1.0 : 1.0\n",
      "        contains(1012mb) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(provide) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(@moosawi17) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(mentally) = False              no : yes    =      1.0 : 1.0\n",
      "          contains(#now) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(rainy) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(anthrax) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(youre) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(#oral) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(chick) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(spray) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(jazdy) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(chicken) = False              no : yes    =      1.0 : 1.0\n",
      "        contains(deluxe) = False              no : yes    =      1.0 : 1.0\n",
      "          contains(memo) = False              no : yes    =      1.0 : 1.0\n",
      "      contains(project.) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(12.9��c) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(quick) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(ignor��) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(15c) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(e10) = False              no : yes    =      1.0 : 1.0\n",
      "       contains(dropout) = False              no : yes    =      1.0 : 1.0\n",
      "         contains(proof) = False              no : yes    =      1.0 : 1.0\n",
      "           contains(500) = False              no : yes    =      1.0 : 1.0\n",
      "    contains(#metoffice) = False              no : yes    =      1.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)\n",
    "\n",
    "# train the classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print classifier.show_most_informative_features(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify London Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(twitter_cleaned)\n",
    "\n",
    "tx = df['text']\n",
    "df['text'] = tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffinal = df[['text']]\n",
    "dffinal['date'] = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student21\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df.index)):\n",
    "    if classifier.classify(extract_features((smart_str(df['text'][i])).split())) == 'yes':\n",
    "        dffinal['text'][i] = smart_str(df['text'][i])\n",
    "    else:\n",
    "        dffinal['text'][i] = None\n",
    "\n",
    "count = 0\n",
    "for i in range(len(df.index)):\n",
    "    if dffinal['text'][i] != None:\n",
    "        count += 1\n",
    "\n",
    "count2 = 0\n",
    "dffinaltrained = pd.DataFrame({'date' : pd.Series(range(count), index=range(count)), 'text' : pd.Series(range(count), index=range(count))})\n",
    "for i in range(len(df.index)):\n",
    "    if dffinal['text'][i] != None:\n",
    "        dffinaltrained['text'][count2] = dffinal['text'][i]\n",
    "        dffinaltrained['date'][count2] = dffinal['date'][i]\n",
    "        count2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8093"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinaltrained['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function which will count the weather words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wordCount(tweet):\n",
    "    # List of words we are looking at\n",
    "    weather_words = ['breeze', 'breezy', 'cloudy', 'cold', 'ice', 'icy', 'icey', 'drizzle', 'frost', 'wind', 'mild', 'dew', \n",
    "                     'freezing', 'downpour', 'shower', 'rain', 'frost', 'nippy', 'hail', 'temperature', 'gail', 'gust',\n",
    "                     'sleet', 'heat', 'storm', 'slush', 'fog', 'foggy', 'flood', 'visibility', 'warm', 'warmer',\n",
    "                     'mist', 'frosty', 'misty', 'chilly', 'thunder', 'lightning', 'snow', 'snowing', 'hot', 'sun', 'sunny',\n",
    "                     'boiling', 'baltic', 'burn']\n",
    "    # Create a new dictionnary\n",
    "    counts = dict()\n",
    "    for t in tweet:\n",
    "        if t in weather_words:\n",
    "            counts[t] = counts.get(t,0) + 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of final clean tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text\n",
       "date            \n",
       "2016-12-14   300\n",
       "2016-12-15   255\n",
       "2016-12-16   795\n",
       "2016-12-19   791\n",
       "2016-12-20   804\n",
       "2016-12-21   421\n",
       "2016-12-22   463\n",
       "2016-12-23   438\n",
       "2016-12-24   447\n",
       "2016-12-25   460\n",
       "2016-12-26   403\n",
       "2016-12-27   404\n",
       "2016-12-28   466\n",
       "2016-12-30   458\n",
       "2016-12-31   482\n",
       "2017-01-01   431\n",
       "2017-01-02   272"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the days and number of tweets per day\n",
    "dffinaltrained.groupby(['date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'2016-12-14', u'2016-12-15', u'2016-12-16', u'2016-12-19',\n",
       "       u'2016-12-20', u'2016-12-21', u'2016-12-22', u'2016-12-23',\n",
       "       u'2016-12-24', u'2016-12-25', u'2016-12-26', u'2016-12-27',\n",
       "       u'2016-12-28', u'2016-12-30', u'2016-12-31', u'2017-01-01',\n",
       "       u'2017-01-02'],\n",
       "      dtype='object', name=u'date')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe with the date\n",
    "tw_date = dffinaltrained.groupby(['date']).count()\n",
    "tw_date.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_date['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going through all tweets then count words and put them in final DataFrame (per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise the final dataframe\n",
    "tw_final = DataFrame()\n",
    "tw_final['date'] = tw_date.index\n",
    "\n",
    "tw_final['Keyword_1'] = None\n",
    "tw_final['Keyword_2'] = None\n",
    "tw_final['Keyword_3'] = None\n",
    "tw_final['Keyword_4'] = None\n",
    "tw_final['Keyword_5'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(tw_date.index)):\n",
    "    df = dffinaltrained[(dffinaltrained['date'] == tw_final['date'][i])]\n",
    "    twitterlist = []\n",
    "    for t in range(len(df.index)):\n",
    "        twitterlist.append(dffinaltrained['text'][t].lower().split())\n",
    "\n",
    "    # Flatten the list so all values in the same list\n",
    "    tweets_flatten = [j for sublist in twitterlist for j in sublist]\n",
    "\n",
    "    # Counting the number of key words in the tweets\n",
    "    d = wordCount(tweets_flatten)\n",
    "    \n",
    "    # give a list of the sorted tweets, with most popular coming first\n",
    "    d2 = sorted(d.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    \n",
    "    tw_final['Keyword_1'][i] = d2[0]#[0]  #keyword 1 is the most popular\n",
    "    tw_final['Keyword_2'][i] = d2[1]#[0]  #keyword 2 is the second most popular\n",
    "    tw_final['Keyword_3'][i] = d2[2]#[0]\n",
    "    tw_final['Keyword_4'][i] = d2[3]#[0]\n",
    "    tw_final['Keyword_5'][i] = d2[4]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Keyword_1</th>\n",
       "      <th>Keyword_2</th>\n",
       "      <th>Keyword_3</th>\n",
       "      <th>Keyword_4</th>\n",
       "      <th>Keyword_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>(fog, 35)</td>\n",
       "      <td>(hot, 33)</td>\n",
       "      <td>(cold, 33)</td>\n",
       "      <td>(sun, 32)</td>\n",
       "      <td>(warm, 17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>(fog, 31)</td>\n",
       "      <td>(hot, 29)</td>\n",
       "      <td>(sun, 28)</td>\n",
       "      <td>(cold, 28)</td>\n",
       "      <td>(warm, 16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>(hot, 74)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "      <td>(cold, 60)</td>\n",
       "      <td>(sun, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>(hot, 74)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "      <td>(cold, 60)</td>\n",
       "      <td>(sun, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>(hot, 76)</td>\n",
       "      <td>(snow, 66)</td>\n",
       "      <td>(cold, 63)</td>\n",
       "      <td>(fog, 61)</td>\n",
       "      <td>(sun, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>(hot, 47)</td>\n",
       "      <td>(sun, 42)</td>\n",
       "      <td>(fog, 42)</td>\n",
       "      <td>(cold, 41)</td>\n",
       "      <td>(warm, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 49)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "      <td>(cold, 43)</td>\n",
       "      <td>(warm, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>(hot, 50)</td>\n",
       "      <td>(fog, 45)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(cold, 41)</td>\n",
       "      <td>(warm, 29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>(hot, 53)</td>\n",
       "      <td>(fog, 46)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(cold, 42)</td>\n",
       "      <td>(warm, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 48)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "      <td>(cold, 43)</td>\n",
       "      <td>(warm, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>(hot, 45)</td>\n",
       "      <td>(fog, 41)</td>\n",
       "      <td>(sun, 40)</td>\n",
       "      <td>(cold, 39)</td>\n",
       "      <td>(warm, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>(hot, 45)</td>\n",
       "      <td>(sun, 41)</td>\n",
       "      <td>(fog, 41)</td>\n",
       "      <td>(cold, 39)</td>\n",
       "      <td>(warm, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 49)</td>\n",
       "      <td>(sun, 46)</td>\n",
       "      <td>(cold, 43)</td>\n",
       "      <td>(warm, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 48)</td>\n",
       "      <td>(sun, 45)</td>\n",
       "      <td>(cold, 42)</td>\n",
       "      <td>(warm, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>(hot, 55)</td>\n",
       "      <td>(fog, 50)</td>\n",
       "      <td>(sun, 47)</td>\n",
       "      <td>(cold, 44)</td>\n",
       "      <td>(warm, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>(hot, 49)</td>\n",
       "      <td>(sun, 44)</td>\n",
       "      <td>(fog, 43)</td>\n",
       "      <td>(cold, 41)</td>\n",
       "      <td>(warm, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>(fog, 34)</td>\n",
       "      <td>(sun, 31)</td>\n",
       "      <td>(hot, 29)</td>\n",
       "      <td>(cold, 29)</td>\n",
       "      <td>(warm, 16)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Keyword_1   Keyword_2   Keyword_3   Keyword_4   Keyword_5\n",
       "0   2016-12-14  (fog, 35)   (hot, 33)  (cold, 33)   (sun, 32)  (warm, 17)\n",
       "1   2016-12-15  (fog, 31)   (hot, 29)   (sun, 28)  (cold, 28)  (warm, 16)\n",
       "2   2016-12-16  (hot, 74)  (snow, 66)   (fog, 61)  (cold, 60)   (sun, 60)\n",
       "3   2016-12-19  (hot, 74)  (snow, 66)   (fog, 61)  (cold, 60)   (sun, 60)\n",
       "4   2016-12-20  (hot, 76)  (snow, 66)  (cold, 63)   (fog, 61)   (sun, 60)\n",
       "5   2016-12-21  (hot, 47)   (sun, 42)   (fog, 42)  (cold, 41)  (warm, 28)\n",
       "6   2016-12-22  (hot, 55)   (fog, 49)   (sun, 45)  (cold, 43)  (warm, 32)\n",
       "7   2016-12-23  (hot, 50)   (fog, 45)   (sun, 44)  (cold, 41)  (warm, 29)\n",
       "8   2016-12-24  (hot, 53)   (fog, 46)   (sun, 44)  (cold, 42)  (warm, 30)\n",
       "9   2016-12-25  (hot, 55)   (fog, 48)   (sun, 45)  (cold, 43)  (warm, 31)\n",
       "10  2016-12-26  (hot, 45)   (fog, 41)   (sun, 40)  (cold, 39)  (warm, 25)\n",
       "11  2016-12-27  (hot, 45)   (sun, 41)   (fog, 41)  (cold, 39)  (warm, 25)\n",
       "12  2016-12-28  (hot, 55)   (fog, 49)   (sun, 46)  (cold, 43)  (warm, 32)\n",
       "13  2016-12-30  (hot, 55)   (fog, 48)   (sun, 45)  (cold, 42)  (warm, 31)\n",
       "14  2016-12-31  (hot, 55)   (fog, 50)   (sun, 47)  (cold, 44)  (warm, 35)\n",
       "15  2017-01-01  (hot, 49)   (sun, 44)   (fog, 43)  (cold, 41)  (warm, 28)\n",
       "16  2017-01-02  (fog, 34)   (sun, 31)   (hot, 29)  (cold, 29)  (warm, 16)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rahul's Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unpivots tw_final\n",
    "tw_final2 = pd.melt(tw_final, id_vars = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(fog, 31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>(hot, 76)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   variable      value\n",
       "0  2016-12-14  Keyword_1  (fog, 35)\n",
       "1  2016-12-15  Keyword_1  (fog, 31)\n",
       "2  2016-12-16  Keyword_1  (hot, 74)\n",
       "3  2016-12-19  Keyword_1  (hot, 74)\n",
       "4  2016-12-20  Keyword_1  (hot, 76)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw_final2.rename(columns = {'variable':'rank'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seperates tuples in value\n",
    "b = []\n",
    "c = []\n",
    "\n",
    "b.extend(a[1] for a in tw_final2['value'])\n",
    "tw_final2['count'] = b\n",
    "\n",
    "c.extend(a[0] for a in tw_final2['value'])\n",
    "tw_final2['value'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>hot</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>hot</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>hot</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank value  count\n",
       "0  2016-12-14  Keyword_1   fog     35\n",
       "1  2016-12-15  Keyword_1   fog     31\n",
       "2  2016-12-16  Keyword_1   hot     74\n",
       "3  2016-12-19  Keyword_1   hot     74\n",
       "4  2016-12-20  Keyword_1   hot     76"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_final2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates dataframe of total tweets for each day\n",
    "df_count = dffinaltrained.groupby(['date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resets index\n",
    "df_count.reset_index(level = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_count.rename(columns = {'text':'total_count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  total_count\n",
       "0  2016-12-14          300\n",
       "1  2016-12-15          255\n",
       "2  2016-12-16          795\n",
       "3  2016-12-19          791\n",
       "4  2016-12-20          804"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joins dataframes tw_final2 and df_count on date\n",
    "merged = pd.merge(tw_final2, df_count, how='inner', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates column for %daily word occurrence\n",
    "merged['%daily word occurrence'] = (merged['count'] / merged['total_count']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.rename(columns = {'value':'Key_word'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>Key_word</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>%daily word occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_1</td>\n",
       "      <td>fog</td>\n",
       "      <td>35</td>\n",
       "      <td>300</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_2</td>\n",
       "      <td>hot</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_3</td>\n",
       "      <td>cold</td>\n",
       "      <td>33</td>\n",
       "      <td>300</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_4</td>\n",
       "      <td>sun</td>\n",
       "      <td>32</td>\n",
       "      <td>300</td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>Keyword_5</td>\n",
       "      <td>warm</td>\n",
       "      <td>17</td>\n",
       "      <td>300</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       rank Key_word  count  total_count  %daily word occurrence\n",
       "0  2016-12-14  Keyword_1      fog     35          300               11.666667\n",
       "1  2016-12-14  Keyword_2      hot     33          300               11.000000\n",
       "2  2016-12-14  Keyword_3     cold     33          300               11.000000\n",
       "3  2016-12-14  Keyword_4      sun     32          300               10.666667\n",
       "4  2016-12-14  Keyword_5     warm     17          300                5.666667"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
